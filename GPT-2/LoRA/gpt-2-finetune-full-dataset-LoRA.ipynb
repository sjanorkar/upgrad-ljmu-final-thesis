{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e320ff09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T02:36:58.533255Z",
     "iopub.status.busy": "2024-07-30T02:36:58.532377Z",
     "iopub.status.idle": "2024-07-30T02:38:51.088427Z",
     "shell.execute_reply": "2024-07-30T02:38:51.087476Z",
     "shell.execute_reply.started": "2024-07-30T02:36:58.533220Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes==0.41.3\n",
      "  Downloading bitsandbytes-0.41.3-py3-none-any.whl.metadata (9.8 kB)\n",
      "Downloading bitsandbytes-0.41.3-py3-none-any.whl (92.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.41.3\n",
      "Collecting peft==0.12.0\n",
      "  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from peft==0.12.0) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from peft==0.12.0) (21.3)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from peft==0.12.0) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from peft==0.12.0) (6.0.1)\n",
      "Collecting torch>=1.13.0 (from peft==0.12.0)\n",
      "  Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting transformers (from peft==0.12.0)\n",
      "  Downloading transformers-4.43.4-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from peft==0.12.0) (4.66.4)\n",
      "Collecting accelerate>=0.21.0 (from peft==0.12.0)\n",
      "  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting safetensors (from peft==0.12.0)\n",
      "  Downloading safetensors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting huggingface-hub>=0.17.0 (from peft==0.12.0)\n",
      "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (2024.6.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (4.12.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->peft==0.12.0) (3.1.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.12.0) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.12.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.12.0) (3.1.4)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.0.0 (from torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.12.0)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers->peft==0.12.0) (2024.5.15)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers->peft==0.12.0)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.12.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.12.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.12.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.12.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.12.0) (2024.6.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.12.0) (1.3.0)\n",
      "Downloading peft-0.12.0-py3-none-any.whl (296 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.1/315.1 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.5/435.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m527.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.43.4-py3-none-any.whl (9.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, safetensors, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, torch, accelerate, peft\n",
      "Successfully installed accelerate-0.33.0 huggingface-hub-0.24.5 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 peft-0.12.0 safetensors-0.4.4 tokenizers-0.19.1 torch-2.4.0 transformers-4.43.4 triton-3.0.0\n",
      "Collecting trl==0.8.6\n",
      "  Downloading trl-0.8.6-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from trl==0.8.6) (2.4.0)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from trl==0.8.6) (4.43.4)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from trl==0.8.6) (1.22.4)\n",
      "Requirement already satisfied: accelerate in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from trl==0.8.6) (0.33.0)\n",
      "Collecting datasets (from trl==0.8.6)\n",
      "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting tyro>=0.5.11 (from trl==0.8.6)\n",
      "  Downloading tyro-0.8.5-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.6) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.6) (4.12.1)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.6) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.6) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.6) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.6) (2024.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.6) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.6) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.6) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.6) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.6) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.6) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.6) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.6) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.6) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.6) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.6) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.6) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl==0.8.6) (12.6.20)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.6) (0.24.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.6) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.6) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.6) (2024.5.15)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.6) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.6) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.6) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.6) (4.66.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docstring-parser>=0.16 (from tyro>=0.5.11->trl==0.8.6)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: rich>=11.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.6) (13.7.1)\n",
      "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.8.6)\n",
      "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from accelerate->trl==0.8.6) (5.9.8)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets->trl==0.8.6) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets->trl==0.8.6) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets->trl==0.8.6) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets->trl==0.8.6) (2.2.2)\n",
      "Collecting xxhash (from datasets->trl==0.8.6)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets->trl==0.8.6) (0.70.16)\n",
      "Collecting fsspec (from torch>=1.4.0->trl==0.8.6)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets->trl==0.8.6) (3.9.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.6) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.6) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.6) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.6) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.6) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.6) (4.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.31.0->trl==0.8.6) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.8.6) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.8.6) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.8.6) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.8.6) (2024.6.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (2.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl==0.8.6) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->datasets->trl==0.8.6) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->datasets->trl==0.8.6) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->datasets->trl==0.8.6) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl==0.8.6) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.8.6) (1.16.0)\n",
      "Downloading trl-0.8.6-py3-none-any.whl (245 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tyro-0.8.5-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.4/103.4 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, shtab, fsspec, docstring-parser, tyro, datasets, trl\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.6.0\n",
      "    Uninstalling fsspec-2024.6.0:\n",
      "      Successfully uninstalled fsspec-2024.6.0\n",
      "Successfully installed datasets-2.20.0 docstring-parser-0.16 fsspec-2024.5.0 shtab-1.7.1 trl-0.8.6 tyro-0.8.5 xxhash-3.4.1\n",
      "Collecting datasets==2.19.2\n",
      "  Downloading datasets-2.19.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets==2.19.2) (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets==2.19.2) (1.22.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets==2.19.2) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets==2.19.2) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets==2.19.2) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets==2.19.2) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets==2.19.2) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets==2.19.2) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets==2.19.2) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets==2.19.2) (0.70.16)\n",
      "Collecting fsspec<=2024.3.1,>=2023.1.0 (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.2)\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets==2.19.2) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets==2.19.2) (0.24.5)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets==2.19.2) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets==2.19.2) (6.0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->datasets==2.19.2) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->datasets==2.19.2) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->datasets==2.19.2) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->datasets==2.19.2) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->datasets==2.19.2) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp->datasets==2.19.2) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets==2.19.2) (4.12.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging->datasets==2.19.2) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.32.1->datasets==2.19.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.32.1->datasets==2.19.2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.32.1->datasets==2.19.2) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.32.1->datasets==2.19.2) (2024.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->datasets==2.19.2) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->datasets==2.19.2) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->datasets==2.19.2) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.19.2) (1.16.0)\n",
      "Downloading datasets-2.19.2-py3-none-any.whl (542 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fsspec, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.5.0\n",
      "    Uninstalling fsspec-2024.5.0:\n",
      "      Successfully uninstalled fsspec-2024.5.0\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.20.0\n",
      "    Uninstalling datasets-2.20.0:\n",
      "      Successfully uninstalled datasets-2.20.0\n",
      "Successfully installed datasets-2.19.2 fsspec-2024.3.1\n",
      "Collecting transformers==4.43.3\n",
      "  Downloading transformers-4.43.3-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers==4.43.3) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers==4.43.3) (0.24.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers==4.43.3) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers==4.43.3) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers==4.43.3) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers==4.43.3) (2024.5.15)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers==4.43.3) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers==4.43.3) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers==4.43.3) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers==4.43.3) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.43.3) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.43.3) (4.12.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.43.3) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers==4.43.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers==4.43.3) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers==4.43.3) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers==4.43.3) (2024.6.2)\n",
      "Downloading transformers-4.43.3-py3-none-any.whl (9.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.43.4\n",
      "    Uninstalling transformers-4.43.4:\n",
      "      Successfully uninstalled transformers-4.43.4\n",
      "Successfully installed transformers-4.43.3\n",
      "Collecting tensorboard==2.17.0\n",
      "  Downloading tensorboard-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard==2.17.0)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard==2.17.0)\n",
      "  Downloading grpcio-1.65.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard==2.17.0)\n",
      "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorboard==2.17.0) (1.22.4)\n",
      "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorboard==2.17.0) (4.25.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorboard==2.17.0) (70.0.0)\n",
      "Requirement already satisfied: six>1.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorboard==2.17.0) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard==2.17.0)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorboard==2.17.0) (3.0.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard==2.17.0) (2.1.5)\n",
      "Downloading tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.65.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Installing collected packages: tensorboard-data-server, markdown, grpcio, absl-py, tensorboard\n",
      "Successfully installed absl-py-2.1.0 grpcio-1.65.4 markdown-3.6 tensorboard-2.17.0 tensorboard-data-server-0.7.2\n",
      "Requirement already satisfied: accelerate==0.33.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.33.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from accelerate==0.33.0) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from accelerate==0.33.0) (21.3)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from accelerate==0.33.0) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from accelerate==0.33.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from accelerate==0.33.0) (2.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from accelerate==0.33.0) (0.24.5)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from accelerate==0.33.0) (0.4.4)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0) (2024.3.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0) (4.12.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.33.0) (3.1.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.33.0) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.33.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.33.0) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.33.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.33.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.33.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.33.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.33.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.33.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.33.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.33.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.33.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.33.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.33.0) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.33.0) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.33.0) (12.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.33.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.33.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.33.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.33.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.33.0) (2024.6.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.33.0) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install bitsandbytes==0.41.3\n",
    "!pip3 install peft==0.12.0\n",
    "!pip3 install trl==0.8.6\n",
    "!pip3 install datasets==2.19.2\n",
    "!pip3 install transformers==4.43.3\n",
    "!pip3 install tensorboard==2.17.0\n",
    "!pip3 install accelerate==0.33.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0498706c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T02:38:54.034117Z",
     "iopub.status.busy": "2024-07-30T02:38:54.033754Z",
     "iopub.status.idle": "2024-07-30T02:39:10.225156Z",
     "shell.execute_reply": "2024-07-30T02:39:10.224350Z",
     "shell.execute_reply.started": "2024-07-30T02:38:54.034089Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    TrainingArguments,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    "    logging,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "703d9acb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T02:39:10.227351Z",
     "iopub.status.busy": "2024-07-30T02:39:10.226782Z",
     "iopub.status.idle": "2024-07-30T02:39:10.233212Z",
     "shell.execute_reply": "2024-07-30T02:39:10.232416Z",
     "shell.execute_reply.started": "2024-07-30T02:39:10.227324Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = \"Vezora/Tested-22k-Python-Alpaca\"\n",
    "model_id = 'openai-community/gpt2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0414d4dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T02:39:10.234737Z",
     "iopub.status.busy": "2024-07-30T02:39:10.234368Z",
     "iopub.status.idle": "2024-07-30T02:39:10.242294Z",
     "shell.execute_reply": "2024-07-30T02:39:10.241516Z",
     "shell.execute_reply.started": "2024-07-30T02:39:10.234703Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_workers = os.cpu_count()\n",
    "max_steps = 3000\n",
    "bf16 = False\n",
    "fp16 = True\n",
    "gradient_accumulation_steps = 2\n",
    "context_length = 256\n",
    "logging_steps = 500\n",
    "save_steps = 500\n",
    "learning_rate = 0.0001\n",
    "out_dir = 'outputs/gpt2_alpaca_preprocess_fn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb98689e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T02:42:59.860762Z",
     "iopub.status.busy": "2024-07-30T02:42:59.860151Z",
     "iopub.status.idle": "2024-07-30T02:42:59.865585Z",
     "shell.execute_reply": "2024-07-30T02:42:59.864628Z",
     "shell.execute_reply.started": "2024-07-30T02:42:59.860728Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_tokenizer(model_id):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True, use_fast=False)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    return tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9cb40b",
   "metadata": {},
   "source": [
    "# Quantization config for QLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e6e63f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T02:39:53.694386Z",
     "iopub.status.busy": "2024-07-30T02:39:53.693428Z",
     "iopub.status.idle": "2024-07-30T02:39:53.700492Z",
     "shell.execute_reply": "2024-07-30T02:39:53.699492Z",
     "shell.execute_reply.started": "2024-07-30T02:39:53.694352Z"
    }
   },
   "outputs": [],
   "source": [
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86121167",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T02:39:55.088643Z",
     "iopub.status.busy": "2024-07-30T02:39:55.087905Z",
     "iopub.status.idle": "2024-07-30T02:39:55.093740Z",
     "shell.execute_reply": "2024-07-30T02:39:55.092730Z",
     "shell.execute_reply.started": "2024-07-30T02:39:55.088612Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model(model_id, is_local=False):\n",
    "    print(\"Loading: \", model_id)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id, \n",
    "        #quantization_config=bnb_config,\n",
    "        device_map={\"\": 0},\n",
    "        local_files_only = is_local)\n",
    "        \n",
    "    model.config.use_cache = False\n",
    "    model.config.pretraining_tp = 1\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e864bd",
   "metadata": {},
   "source": [
    "# Generate Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "656b706a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T03:48:03.605263Z",
     "iopub.status.busy": "2024-07-30T03:48:03.604501Z",
     "iopub.status.idle": "2024-07-30T03:48:03.611328Z",
     "shell.execute_reply": "2024-07-30T03:48:03.610119Z",
     "shell.execute_reply.started": "2024-07-30T03:48:03.605231Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_inference(model, tokenizer):\n",
    "    pipe = pipeline(task='text-generation', model=model, tokenizer=tokenizer, max_length=256)\n",
    "\n",
    "    for prompt in prompts:\n",
    "        result = pipe(prompt)\n",
    "        print(\"******************************* PROMPT *******************************\")\n",
    "        print(prompt)\n",
    "        print(\"******************************* Inference *******************************\")\n",
    "        print(result[0]['generated_text'])\n",
    "        print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae167201",
   "metadata": {},
   "source": [
    "# Inference Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f0b01ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T03:48:05.609086Z",
     "iopub.status.busy": "2024-07-30T03:48:05.608421Z",
     "iopub.status.idle": "2024-07-30T03:48:05.615809Z",
     "shell.execute_reply": "2024-07-30T03:48:05.614701Z",
     "shell.execute_reply.started": "2024-07-30T03:48:05.609058Z"
    }
   },
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"\"\"Can you design a program in Python that can predict the likelihood of a certain material becoming unstable under high pressure and temperature conditions? This can be calculated using the Gurney equation, which takes into account parameters such as the chemical composition and crystal structure of the material. Additionally, can you provide a real-world scenario where this program could be applied in the field of material science and engineering?\"\"\",\n",
    "    \"\"\"Write a Python function that returns the maximum value of the given set of integers: 1, 5, 23, and 9. The function should only use one line of code and must utilize the lambda function. Additionally, the function should be able to handle any set of integers provided as input, and should return an error message if any non-integer values are detected. The output should be displayed in a formatted table with the following columns: \"Input Set\", \"Maximum Value\". The table should also include a row for the given set of integers as well as a row for a randomly generated set of 10 integers between 1 and 100. Lastly, the function should be written in SQL and should be able to query a database table containing the input sets and their corresponding maximum values.\"\"\",\n",
    "    \"\"\"Create a function that takes two parameters, a number and a string, and returns an array with those two values in it. The string parameter should be checked if it is a valid string and if it contains only alphabetical characters. If the string is not valid (length less than 10 characters) or contains non-alphabetical characters, the function should return an empty array. Additionally, the number parameter should be restricted to a range between -1000 and 1000 (inclusive). The function should also check if the number is a prime number and return an empty array if it is not.\"\"\",\n",
    "    \"\"\"Given a string, convert it to upper case using only basic string manipulation operations. The string may contain punctuation marks, special characters, and spaces. String: This string should be in upper case!\"\"\",\n",
    "    \"\"\"Find the sum of the first 1000 prime numbers that are greater than 100.\"\"\",\n",
    "    \"\"\"Provide a function that finds the length of a string, but without using any built-in string length functions or methods, and without using any iteration or recursion.\"\"\",\n",
    "    \"\"\"Create a function that removes duplicates from an array and returns an array of the unique values. The function should only use O(1) additional space and have a time complexity of O(n), where n is the length of the input array. The input array can contain integers, floating-point numbers, strings, and nested arrays. The output array should be sorted in descending order. Additionally, the function should handle nested arrays correctly by recursively flattening them before removing duplicates.\"\"\",\n",
    "    \"\"\"Create a 3x4 NumPy array of random integers from 0 to 5, where each row should have at least one unique value.\"\"\",\n",
    "    \"\"\"Find the index of the element 'c' in the following list, but the list may contain duplicates and the element 'c' may appear multiple times.\"\"\",\n",
    "    \"\"\"Write a function for finding the minimum value in a given array, with a time complexity requirement of O(n log n), where n is the length of the array.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668e55f4",
   "metadata": {},
   "source": [
    "# Pre Fine-tuning inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50013260",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T03:48:07.439699Z",
     "iopub.status.busy": "2024-07-30T03:48:07.439219Z",
     "iopub.status.idle": "2024-07-30T03:48:37.148520Z",
     "shell.execute_reply": "2024-07-30T03:48:37.147545Z",
     "shell.execute_reply.started": "2024-07-30T03:48:07.439667Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:  openai-community/gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************* PROMPT *******************************\n",
      "Can you design a program in Python that can predict the likelihood of a certain material becoming unstable under high pressure and temperature conditions? This can be calculated using the Gurney equation, which takes into account parameters such as the chemical composition and crystal structure of the material. Additionally, can you provide a real-world scenario where this program could be applied in the field of material science and engineering?\n",
      "******************************* Inference *******************************\n",
      "Can you design a program in Python that can predict the likelihood of a certain material becoming unstable under high pressure and temperature conditions? This can be calculated using the Gurney equation, which takes into account parameters such as the chemical composition and crystal structure of the material. Additionally, can you provide a real-world scenario where this program could be applied in the field of material science and engineering? Would a specific kind of material that could be used to predict or control conditions are the basis for your proposed program? In terms of the question of temperature, would a given material have the properties described by the Gurney equation change under high pressure and/or temperature conditions using some of the parameters described in the laboratory paper? One example of what you would use depends upon the specific application such as reducing the boiling temperature of a non-magnetic metallic such as aluminum, while another is to decrease the melting efficiency of a magnetic metallic such as silicon. Should Gurney be chosen as the parameter of your proposed program for any parameter, then can you specify which is most appropriate for that parameter? My understanding is that these and many other parameters would probably result in the following parameters in your program - and you would only use them if it is well known which one corresponds to what the desired parameters\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Write a Python function that returns the maximum value of the given set of integers: 1, 5, 23, and 9. The function should only use one line of code and must utilize the lambda function. Additionally, the function should be able to handle any set of integers provided as input, and should return an error message if any non-integer values are detected. The output should be displayed in a formatted table with the following columns: \"Input Set\", \"Maximum Value\". The table should also include a row for the given set of integers as well as a row for a randomly generated set of 10 integers between 1 and 100. Lastly, the function should be written in SQL and should be able to query a database table containing the input sets and their corresponding maximum values.\n",
      "******************************* Inference *******************************\n",
      "Write a Python function that returns the maximum value of the given set of integers: 1, 5, 23, and 9. The function should only use one line of code and must utilize the lambda function. Additionally, the function should be able to handle any set of integers provided as input, and should return an error message if any non-integer values are detected. The output should be displayed in a formatted table with the following columns: \"Input Set\", \"Maximum Value\". The table should also include a row for the given set of integers as well as a row for a randomly generated set of 10 integers between 1 and 100. Lastly, the function should be written in SQL and should be able to query a database table containing the input sets and their corresponding maximum values.\n",
      "\n",
      "Sorting (optional)\n",
      "\n",
      "Set of integers to list of values with sorted lists of values: 5, 27, 24, 13, 7, 9. The program may display a small \"sort by values\" box which lists the specified set of integers as a result of a given input. The program should also report a complete set of values. The program should also report the number of values.\n",
      "\n",
      "Reverse-Code\n",
      "\n",
      "Reverse-Code of a function or function class\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Create a function that takes two parameters, a number and a string, and returns an array with those two values in it. The string parameter should be checked if it is a valid string and if it contains only alphabetical characters. If the string is not valid (length less than 10 characters) or contains non-alphabetical characters, the function should return an empty array. Additionally, the number parameter should be restricted to a range between -1000 and 1000 (inclusive). The function should also check if the number is a prime number and return an empty array if it is not.\n",
      "******************************* Inference *******************************\n",
      "Create a function that takes two parameters, a number and a string, and returns an array with those two values in it. The string parameter should be checked if it is a valid string and if it contains only alphabetical characters. If the string is not valid (length less than 10 characters) or contains non-alphabetical characters, the function should return an empty array. Additionally, the number parameter should be restricted to a range between -1000 and 1000 (inclusive). The function should also check if the number is a prime number and return an empty array if it is not.\n",
      "\n",
      "Function: return a variable that can be passed in as a parameter to a function (except for the use of the `--return' option).\n",
      "\n",
      "Parameters\n",
      "\n",
      "Parameter Range Description a number for the list\n",
      "\n",
      "var a[]: a constant\n",
      "\n",
      "parameter Parameter Range Description a integer optional: '--value' to set the value of a parameter (optional) '--len' to return the length of the specified array. '--len' is equivalent to `+', but with `+' characters. See the --len list for the recommended behavior. Returns a variable that can be passed in as a parameter to a function (except for the use of\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Given a string, convert it to upper case using only basic string manipulation operations. The string may contain punctuation marks, special characters, and spaces. String: This string should be in upper case!\n",
      "******************************* Inference *******************************\n",
      "Given a string, convert it to upper case using only basic string manipulation operations. The string may contain punctuation marks, special characters, and spaces. String: This string should be in upper case! The same operation applied to characters outside the string will generate a null character. This will not work for ASCII and ASCII-5 characters. If the string is not empty, it will always be a null character.\n",
      "\n",
      "The string is placed at the bottom of its array by applying an optional colon to it.\n",
      "\n",
      "Returns a string of the character at the lower case first order. If a string is greater than zero, the range is rounded to equal its largest length.\n",
      "\n",
      "Returns The array of characters to place at the same location on both ends of the string.\n",
      "\n",
      "❖ type StringArray []\n",
      "\n",
      "Returns a list of strings and a list of strings and a set of strings and a string and a string to be placed at the same location on both ends of it.\n",
      "\n",
      "Returns A list of strings and a list of strings and an array containing values for the integers in order.\n",
      "\n",
      "❖ type StringList []\n",
      "\n",
      "Returns a List and a List of strings.\n",
      "\n",
      "❖ type String []Object\n",
      "\n",
      "Returns a String object with\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Find the sum of the first 1000 prime numbers that are greater than 100.\n",
      "******************************* Inference *******************************\n",
      "Find the sum of the first 1000 prime numbers that are greater than 100. Then convert the first 1000 prime numbers to their average frequency. The more prime numbers in your head, the easier it is to find out what makes a prime number high or low.\n",
      "\n",
      "In the previous examples, an early prime is 10 times or less than 11 times the size of the current prime. In this case, if we divide 2 by 2, say 1/5, then multiplying this by -11 makes 2 11. So that gives the number 4 times 4. If the number 2 is 3 times 3 as large as 2 and 2 times 2, then multiplying this by -11 makes 4 3 7. In fact, if I had multiplied 3 times 3 by 5 in one go, then 4 3 7 is only about half 5, but it's still pretty strong compared to 2 1/5. So this is exactly how prime numbers might appear.\n",
      "\n",
      "You can also use the other factors that add up to the number of times your head is going to be engaged with prime numbers such as time and number of digits. In other words: The more of an odd number there may be, the bigger your focus is going to be.\n",
      "\n",
      "One particular number, however. It's\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************* PROMPT *******************************\n",
      "Provide a function that finds the length of a string, but without using any built-in string length functions or methods, and without using any iteration or recursion.\n",
      "******************************* Inference *******************************\n",
      "Provide a function that finds the length of a string, but without using any built-in string length functions or methods, and without using any iteration or recursion. For a single invocation of this method it is required that the string length (or an extension thereof) be used as part of the invocation. This must be done by calling the function with the length as that length argument.\n",
      "\n",
      "The following example will try to generate a single empty string:\n",
      "\n",
      "import math class Strings([ string ]) { def length_to_string = str. to_hex ( '0' ) if length_to_string >= 0 { return len ( string ) - length_to_string } if length_to_string > length_of_string else { return - 1 } return length_of_string } val bytes = bytes. put_str ( bytes [ 1 ])\n",
      "\n",
      "Here is an example of the following code using string literals:\n",
      "\n",
      ">>> print \"Please enter #{sparse.string(strings)+1}\" >>> print \"Your character is #{sparse.string(bytes)}\". to_hex_by_byte ( '0')\n",
      "\n",
      "See also\n",
      "\n",
      "A single function that sets the length of string (\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Create a function that removes duplicates from an array and returns an array of the unique values. The function should only use O(1) additional space and have a time complexity of O(n), where n is the length of the input array. The input array can contain integers, floating-point numbers, strings, and nested arrays. The output array should be sorted in descending order. Additionally, the function should handle nested arrays correctly by recursively flattening them before removing duplicates.\n",
      "******************************* Inference *******************************\n",
      "Create a function that removes duplicates from an array and returns an array of the unique values. The function should only use O(1) additional space and have a time complexity of O(n), where n is the length of the input array. The input array can contain integers, floating-point numbers, strings, and nested arrays. The output array should be sorted in descending order. Additionally, the function should handle nested arrays correctly by recursively flattening them before removing duplicates.\n",
      "\n",
      "The method O(1) is used by a function to return an array of the unique values where duplicate information is passed to the function with the number of digits. If this value is out of sequence, the input array is not truncated. (Note: Duplicates are included in the original input array.) The output array is an input sequence of sequence numbers of hexadecimal digits.\n",
      "\n",
      "The method O(n) is used by the function to return the unique number (represented as a number in the input array) of n and the key value of the associated pointer. If N < 0, the function returns a zero-terminated null pointer. The function shall return a value of its own.\n",
      "\n",
      "Each element of the resulting array may have the\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Create a 3x4 NumPy array of random integers from 0 to 5, where each row should have at least one unique value.\n",
      "******************************* Inference *******************************\n",
      "Create a 3x4 NumPy array of random integers from 0 to 5, where each row should have at least one unique value. By default, the first row is the first one set. You can add 2, in 1 case, by adding 1 row.\n",
      "\n",
      "For example, here is the \"3x4 string\" from 1 to 3, or to be more specific:\n",
      "\n",
      "2 3 4 5 7\n",
      "\n",
      "What if you are searching the web for \"3x4 string\" for the value 5? Perhaps you find the following results:\n",
      "\n",
      "Number of characters: 1 (10), (3)\n",
      "\n",
      "Number of characters in hexadecimal ASCII mode: 18 (0,00 and 1)\n",
      "\n",
      "Number of characters in hexadecimal ASCII mode: 15 (1,5)\n",
      "\n",
      "Number of characters in number of digits: 33 (2,4)\n",
      "\n",
      "Number of digits in numbers of sub-expressions: -9 (3)\n",
      "\n",
      "And here are 5 of the 3 characters from \"3x4 string\" back in 1999:\n",
      "\n",
      "0 1 2 13 1 3 18 13 9 3 15 13 3\n",
      "\n",
      "That's almost exactly two characters every 8+ characters. The length of a string is 3\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Find the index of the element 'c' in the following list, but the list may contain duplicates and the element 'c' may appear multiple times.\n",
      "******************************* Inference *******************************\n",
      "Find the index of the element 'c' in the following list, but the list may contain duplicates and the element 'c' may appear multiple times. If you wish to exclude a reference to `this::element' from the list, use `this::list::add()`.\n",
      "\n",
      "Returns an index of the element with the same name as the element 'this::element' in the list. If an element appears multiple times on the list, use `this::list::add()`.\n",
      "\n",
      "Example\n",
      "\n",
      "This function lists the list of elements with the same attributes as it does for a given element. The following code is equivalent to the following:\n",
      "\n",
      "void let_last_tag = (this::get_in_category(), this::get_in_category()); let list_tags = this::find_tag(this) + <= list_tags.append();\n",
      "\n",
      "In general, the following code will return a list which contains all elements with the same name. Note however, that the above code does not do so for all elements listed in the example.\n",
      "\n",
      "let_last_category = list_tags.first(); let tags = this::find_tag(tag); let list_tags = this::find_\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Write a function for finding the minimum value in a given array, with a time complexity requirement of O(n log n), where n is the length of the array.\n",
      "******************************* Inference *******************************\n",
      "Write a function for finding the minimum value in a given array, with a time complexity requirement of O(n log n), where n is the length of the array. It works in O(1) but is better on platforms like ARM (which has 32-bit processors).\n",
      "\n",
      "Now for the fun part. The function does its evaluation at the beginning of the input type. This is how the code will look like with the following C++ C++ header:\n",
      "\n",
      "class InputC: public void find(std::string input) { // we don't see our input in input. String data = Get-Content(0) << 12; int len = input.len - input.len;... if (len > 16) - = data; else - = 0; String sic = String::fromChar32(input);... }\n",
      "\n",
      "The code looks like this:\n",
      "\n",
      "class InputC: public void find(std::string input) { data = Get-Content(0) << 12; int len = input.len - input.len; for (int i = 1; i < input.length; i++) { if (data[i] >= len || data[i] < len + 2) { data =\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = load_model(model_id) \n",
    "tokenizer = load_tokenizer(model_id)\n",
    "generate_inference(model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae8d4aa",
   "metadata": {},
   "source": [
    "# PEFT Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8470ed3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T02:40:52.157778Z",
     "iopub.status.busy": "2024-07-30T02:40:52.157513Z",
     "iopub.status.idle": "2024-07-30T02:40:52.163191Z",
     "shell.execute_reply": "2024-07-30T02:40:52.162245Z",
     "shell.execute_reply.started": "2024-07-30T02:40:52.157755Z"
    }
   },
   "outputs": [],
   "source": [
    "LORA_R = 16\n",
    "LORA_ALPHA = 32\n",
    "LORA_DROPOUT= 0.05\n",
    "LORA_TARGET_MODULES = [\n",
    "    \"q_proj\",\n",
    "    \"k_proj\",\n",
    "    \"v_proj\",\n",
    "    \"o_proj\",\n",
    "    \"gate_proj\",\n",
    "    \"up_proj\",\n",
    "    \"down_proj\",\n",
    "    \"lm_head\",\n",
    "]\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "MICRO_BATCH_SIZE = 4\n",
    "GRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE\n",
    "LEARNING_RATE = 3e-4\n",
    "TRAIN_STEPS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e65b6b3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T02:41:01.114652Z",
     "iopub.status.busy": "2024-07-30T02:41:01.114235Z",
     "iopub.status.idle": "2024-07-30T02:41:01.119775Z",
     "shell.execute_reply": "2024-07-30T02:41:01.118879Z",
     "shell.execute_reply.started": "2024-07-30T02:41:01.114618Z"
    }
   },
   "outputs": [],
   "source": [
    "peft_params = LoraConfig(\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    target_modules=LORA_TARGET_MODULES,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6418daf2",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4304317",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T02:41:02.950764Z",
     "iopub.status.busy": "2024-07-30T02:41:02.950010Z",
     "iopub.status.idle": "2024-07-30T02:41:02.955201Z",
     "shell.execute_reply": "2024-07-30T02:41:02.954304Z",
     "shell.execute_reply.started": "2024-07-30T02:41:02.950732Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_function(example):\n",
    "    \"\"\"\n",
    "    Formatting function returning a list of samples (kind of necessary for SFT API).\n",
    "    \"\"\"\n",
    "    text = f\"### Instruction:\\n{example['instruction']}\\n\\n### Input:\\n{example['input']}\\n\\n### Response:\\n{example['output']}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "742d8109",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T02:41:04.346174Z",
     "iopub.status.busy": "2024-07-30T02:41:04.345383Z",
     "iopub.status.idle": "2024-07-30T02:41:12.389168Z",
     "shell.execute_reply": "2024-07-30T02:41:12.388379Z",
     "shell.execute_reply.started": "2024-07-30T02:41:04.346141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8bc93e2a0d94b0396c2f22c05f75905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/4.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1830c55914b842dca00745bc1cf9aee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/49.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb8be02db39423f9411641bdcc85fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/22608 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ea9324b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T02:41:12.390935Z",
     "iopub.status.busy": "2024-07-30T02:41:12.390641Z",
     "iopub.status.idle": "2024-07-30T02:41:12.502142Z",
     "shell.execute_reply": "2024-07-30T02:41:12.501425Z",
     "shell.execute_reply.started": "2024-07-30T02:41:12.390910Z"
    }
   },
   "outputs": [],
   "source": [
    "train_val = dataset[\"train\"].train_test_split(\n",
    "    test_size=2200, shuffle=True, seed=42\n",
    ")\n",
    "train_dataset = train_val[\"train\"]\n",
    "eval_dataset = train_val[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15319e4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T02:41:13.768191Z",
     "iopub.status.busy": "2024-07-30T02:41:13.767815Z",
     "iopub.status.idle": "2024-07-30T02:41:13.776711Z",
     "shell.execute_reply": "2024-07-30T02:41:13.775730Z",
     "shell.execute_reply.started": "2024-07-30T02:41:13.768165Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['instruction', 'input', 'output'],\n",
       "     num_rows: 20408\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['instruction', 'input', 'output'],\n",
       "     num_rows: 2200\n",
       " }))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41369aaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T02:43:04.527779Z",
     "iopub.status.busy": "2024-07-30T02:43:04.527413Z",
     "iopub.status.idle": "2024-07-30T02:43:06.310562Z",
     "shell.execute_reply": "2024-07-30T02:43:06.309456Z",
     "shell.execute_reply.started": "2024-07-30T02:43:04.527753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 816,400 || all params: 125,256,208 || trainable%: 0.6518\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_params)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "for param in model.parameters():\n",
    "    if param.requires_grad:\n",
    "        param.data = param.data.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c1fb63",
   "metadata": {},
   "source": [
    "# Training Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6610dcf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T02:43:57.950731Z",
     "iopub.status.busy": "2024-07-30T02:43:57.950204Z",
     "iopub.status.idle": "2024-07-30T02:43:57.978574Z",
     "shell.execute_reply": "2024-07-30T02:43:57.977644Z",
     "shell.execute_reply.started": "2024-07-30T02:43:57.950698Z"
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR=\"/home/ec2-user/SageMaker/gpt-2/LoRA\"\n",
    "#OUTPUT_DIR=\"/kaggle/working/gpt-2\"\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=OUTPUT_DIR,\n",
    "  num_train_epochs=3,\n",
    "  per_device_train_batch_size=4,\n",
    "  per_device_eval_batch_size=4,\n",
    "  gradient_accumulation_steps=4,\n",
    "  optim=\"paged_adamw_32bit\",\n",
    "  save_steps=500,\n",
    "  logging_steps=500,\n",
    "  learning_rate=0.0001,\n",
    "  eval_strategy=\"steps\",\n",
    "  weight_decay=0.001,\n",
    "  fp16=True,\n",
    "  bf16=False,\n",
    "  max_grad_norm=0.3,\n",
    "  max_steps=-1,\n",
    "  warmup_ratio=0.03,\n",
    "  group_by_length=True,\n",
    "  lr_scheduler_type=\"constant\",\n",
    "  report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3080151",
   "metadata": {},
   "source": [
    "# model trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6f4f16a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T02:43:59.377418Z",
     "iopub.status.busy": "2024-07-30T02:43:59.376789Z",
     "iopub.status.idle": "2024-07-30T02:45:56.864060Z",
     "shell.execute_reply": "2024-07-30T02:45:56.863285Z",
     "shell.execute_reply.started": "2024-07-30T02:43:59.377387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248e07239b1e479f9f715c1d9fd35086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2721 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929e254ba22d4cfe9cf143f5245d7b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    max_seq_length=context_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    formatting_func=preprocess_function,\n",
    "    packing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef9ec78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset 4 finetuning 1722934497564\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "current_timestamp_ms = int(time.time() * 1000)\n",
    "print(\"dataset 4 finetuning\", current_timestamp_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05543664",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T02:45:59.859073Z",
     "iopub.status.busy": "2024-07-30T02:45:59.858702Z",
     "iopub.status.idle": "2024-07-30T03:42:00.328566Z",
     "shell.execute_reply": "2024-07-30T03:42:00.327676Z",
     "shell.execute_reply.started": "2024-07-30T02:45:59.859044Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9747' max='9747' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9747/9747 27:36, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.497700</td>\n",
       "      <td>2.038632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.281300</td>\n",
       "      <td>1.952713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.203900</td>\n",
       "      <td>1.896765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.153400</td>\n",
       "      <td>1.859835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>1.830957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.094900</td>\n",
       "      <td>1.811611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>2.071800</td>\n",
       "      <td>1.793988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.051000</td>\n",
       "      <td>1.780530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>2.039500</td>\n",
       "      <td>1.768623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.026800</td>\n",
       "      <td>1.759882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>2.017200</td>\n",
       "      <td>1.749025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.000500</td>\n",
       "      <td>1.739876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.983200</td>\n",
       "      <td>1.732107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.983800</td>\n",
       "      <td>1.725110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.974900</td>\n",
       "      <td>1.718581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.977900</td>\n",
       "      <td>1.712959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.953900</td>\n",
       "      <td>1.708537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.962600</td>\n",
       "      <td>1.704137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.953300</td>\n",
       "      <td>1.699416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    }
   ],
   "source": [
    "history = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f33e3177",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T03:43:05.431525Z",
     "iopub.status.busy": "2024-07-30T03:43:05.431133Z",
     "iopub.status.idle": "2024-07-30T03:43:05.745542Z",
     "shell.execute_reply": "2024-07-30T03:43:05.744602Z",
     "shell.execute_reply.started": "2024-07-30T03:43:05.431492Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/ec2-user/SageMaker/gpt-2/LoRA/fine_tuned/tokenizer_config.json',\n",
       " '/home/ec2-user/SageMaker/gpt-2/LoRA/fine_tuned/special_tokens_map.json',\n",
       " '/home/ec2-user/SageMaker/gpt-2/LoRA/fine_tuned/vocab.json',\n",
       " '/home/ec2-user/SageMaker/gpt-2/LoRA/fine_tuned/merges.txt',\n",
       " '/home/ec2-user/SageMaker/gpt-2/LoRA/fine_tuned/added_tokens.json')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(f\"{OUTPUT_DIR}/fine_tuned\")\n",
    "tokenizer.save_pretrained(f\"{OUTPUT_DIR}/fine_tuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf66a55",
   "metadata": {},
   "source": [
    "# post fine-tuning inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac647cfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T03:50:03.635866Z",
     "iopub.status.busy": "2024-07-30T03:50:03.635178Z",
     "iopub.status.idle": "2024-07-30T03:50:36.590654Z",
     "shell.execute_reply": "2024-07-30T03:50:36.589649Z",
     "shell.execute_reply.started": "2024-07-30T03:50:03.635832Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:  /home/ec2-user/SageMaker/gpt-2/LoRA/fine_tuned/\n",
      "******************************* PROMPT *******************************\n",
      "Can you design a program in Python that can predict the likelihood of a certain material becoming unstable under high pressure and temperature conditions? This can be calculated using the Gurney equation, which takes into account parameters such as the chemical composition and crystal structure of the material. Additionally, can you provide a real-world scenario where this program could be applied in the field of material science and engineering?\n",
      "******************************* Inference *******************************\n",
      "Can you design a program in Python that can predict the likelihood of a certain material becoming unstable under high pressure and temperature conditions? This can be calculated using the Gurney equation, which takes into account parameters such as the chemical composition and crystal structure of the material. Additionally, can you provide a real-world scenario where this program could be applied in the field of material science and engineering?\n",
      "Using this method, the Gurney equation assumes a linear function of temperature, water vapor and fluid pressure, where temperature is the constant and pressure the fractionally larger the mass of atoms. In addition, both water vapor and water pressure are negative if they come into contact with any surface materials, including rocks, gas, organic materials, gases and even metals.\n",
      "### Input:\n",
      "\n",
      "\n",
      "### Response:\n",
      "-\n",
      " \n",
      "### Input:\n",
      "To solve this problem, the Gurney equation used in this implementation contains a number of potential parameters that can be used to predict the stability of materials within a given pressure range. These include: the mass of each material, its distribution, relative humidity, pressure, etc. and the number of atoms that need to be kept under pressure and temperatures to produce stable materials.\n",
      "Please be aware that the Gurney equation contains many potential\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Write a Python function that returns the maximum value of the given set of integers: 1, 5, 23, and 9. The function should only use one line of code and must utilize the lambda function. Additionally, the function should be able to handle any set of integers provided as input, and should return an error message if any non-integer values are detected. The output should be displayed in a formatted table with the following columns: \"Input Set\", \"Maximum Value\". The table should also include a row for the given set of integers as well as a row for a randomly generated set of 10 integers between 1 and 100. Lastly, the function should be written in SQL and should be able to query a database table containing the input sets and their corresponding maximum values.\n",
      "******************************* Inference *******************************\n",
      "Write a Python function that returns the maximum value of the given set of integers: 1, 5, 23, and 9. The function should only use one line of code and must utilize the lambda function. Additionally, the function should be able to handle any set of integers provided as input, and should return an error message if any non-integer values are detected. The output should be displayed in a formatted table with the following columns: \"Input Set\", \"Maximum Value\". The table should also include a row for the given set of integers as well as a row for a randomly generated set of 10 integers between 1 and 100. Lastly, the function should be written in SQL and should be able to query a database table containing the input sets and their corresponding maximum values.\n",
      "\n",
      "### Input: 60000, 1, 4, and 5\n",
      "   result.choice(): 1\n",
      "   print(result.choice()))\n",
      "\n",
      "The function should handle any strings that contain any ASCII character.\n",
      "\n",
      "### Input: 70000, 16, 4, 5, and 6\n",
      "  result.choice(): 1\n",
      "   print(result.compute(1)))\n",
      " \n",
      "The function should handle any input strings by using the string() function from the time complexity module\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Create a function that takes two parameters, a number and a string, and returns an array with those two values in it. The string parameter should be checked if it is a valid string and if it contains only alphabetical characters. If the string is not valid (length less than 10 characters) or contains non-alphabetical characters, the function should return an empty array. Additionally, the number parameter should be restricted to a range between -1000 and 1000 (inclusive). The function should also check if the number is a prime number and return an empty array if it is not.\n",
      "******************************* Inference *******************************\n",
      "Create a function that takes two parameters, a number and a string, and returns an array with those two values in it. The string parameter should be checked if it is a valid string and if it contains only alphabetical characters. If the string is not valid (length less than 10 characters) or contains non-alphabetical characters, the function should return an empty array. Additionally, the number parameter should be restricted to a range between -1000 and 1000 (inclusive). The function should also check if the number is a prime number and return an empty array if it is not.\n",
      "\n",
      "### Input:\n",
      "\n",
      "\n",
      "### Response:\n",
      "To the `arr1` function:\n",
      " \n",
      "#\n",
      "list_array = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "\n",
      "#\n",
      "def list_arr1(arr1):\n",
      " \" The sum of the largest numbers that can be stored in the `arr1` array.\n",
      "   # The string parameter should be checked if it is a valid string and if it contains only alphabetical characters.\n",
      "\n",
      "print(item[1])\n",
      "\n",
      "\n",
      "def index():\n",
      "\n",
      "    # The number parameter should be restricted to a maximum of 1000, and the function\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Given a string, convert it to upper case using only basic string manipulation operations. The string may contain punctuation marks, special characters, and spaces. String: This string should be in upper case!\n",
      "******************************* Inference *******************************\n",
      "Given a string, convert it to upper case using only basic string manipulation operations. The string may contain punctuation marks, special characters, and spaces. String: This string should be in upper case!\n",
      "5. Regular expressions A regular expression is a structure containing any character and any punctuation marks as well as any special characters that can be punctuated. For example, one regular expression may contain punctuation marks, while a string contains special characters as a space. The regular expression should only contain punctuation marks to keep the reader informed of punctuation marks and special characters. The special character format should be set to uppercase to avoid exceeding the desired length.\n",
      "6. Special characters and any punctuation marks\n",
      "1. Insert a punctuation mark into a string without using any special syntax functions, such as check marks or space marks.\n",
      "2. Repeat the pattern in a space, using only basic arithmetic operations to ensure that the character-pattern is separated from the input string without using any special input code.\n",
      "3. Parse a string in lowercase using only basic arithmetic operations. Each string should have one or more special characters that can be punctuated. The final indentation of each string should be checked if necessary to ensure that the character-pattern is complete\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Find the sum of the first 1000 prime numbers that are greater than 100.\n",
      "******************************* Inference *******************************\n",
      "Find the sum of the first 1000 prime numbers that are greater than 100. Additionally, find the length of the prime number if it is greater than 1000 and the length of the prime number if it is less than 0.\n",
      "\n",
      "\n",
      "### Input a hash of strings consisting of the given string and all their digits and the strings' starting positions. The output should be a list of integers.\n",
      " \n",
      "### Display a function as an empty string\n",
      " \n",
      "2 = 0\n",
      "\n",
      "\n",
      "### Sort the string by the length of the string first and compare it with the total length. The function should be implemented using `sort_of', sort_of_by = True or else `sort_of=True`, as in `sort_of=True`, it should be implemented using `find_str_of_string(length=len, length=1000)`.\n",
      "\n",
      "-[\n",
      "[\n",
      "\n",
      "sorted_of(sum=True, length=101)\n",
      " ]\n",
      "\n",
      "Output:\n",
      "\n",
      "# Return `ToStr2(length=101):1`\n",
      "print(to_str_of_string)\n",
      "\n",
      "-[sorted_of(sum=True, length=101)\n",
      "import random\n",
      "\n",
      "sorted_of=True\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************* PROMPT *******************************\n",
      "Provide a function that finds the length of a string, but without using any built-in string length functions or methods, and without using any iteration or recursion.\n",
      "******************************* Inference *******************************\n",
      "Provide a function that finds the length of a string, but without using any built-in string length functions or methods, and without using any iteration or recursion. Instead, you can simply use the built-in function to find the string you want to find, and handle all the rest. For example:\n",
      "```python\n",
      "def find_string(string):     # Find the first character in string\n",
      "    else:       filename = \"\"\n",
      "             return string.lower()\n",
      "```\n",
      "\n",
      "The function returns True if it finds a string, or False otherwise.\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Create a function that removes duplicates from an array and returns an array of the unique values. The function should only use O(1) additional space and have a time complexity of O(n), where n is the length of the input array. The input array can contain integers, floating-point numbers, strings, and nested arrays. The output array should be sorted in descending order. Additionally, the function should handle nested arrays correctly by recursively flattening them before removing duplicates.\n",
      "******************************* Inference *******************************\n",
      "Create a function that removes duplicates from an array and returns an array of the unique values. The function should only use O(1) additional space and have a time complexity of O(n), where n is the length of the input array. The input array can contain integers, floating-point numbers, strings, and nested arrays. The output array should be sorted in descending order. Additionally, the function should handle nested arrays correctly by recursively flattening them before removing duplicates. Additionally, ensure that the helper function should remove duplicate elements before recursively flattening. Additionally, ensure that the function should also remove duplicate references or arrays, ensuring even recursion and memory efficiency. Additionally, ensuring that the helper function handles duplicates effectively should ensure that the helper function can be overridden with custom functionality should ensure that the function is implemented in a way that accomplishes this. Additionally, ensure that the function should handle duplicates correctly by recursively flattening duplicates. Additionally, ensure that the function should also handle duplicates by recursively flattening duplicates. Additionally, ensure that the function handles duplicates correctly by recursively flattening duplicates. Additionally, ensure that the function handles duplicates correctly by recursively flattening duplicates.\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Create a 3x4 NumPy array of random integers from 0 to 5, where each row should have at least one unique value.\n",
      "******************************* Inference *******************************\n",
      "Create a 3x4 NumPy array of random integers from 0 to 5, where each row should have at least one unique value. The first row should have multiple unique values as well as the second one should have multiple unique values as well as an empty list.\n",
      "```python\n",
      "import math\n",
      "    {\"name\": 7, \"age\": 15},\n",
      "    \"date\": 10831948,\n",
      "   \"date_start\": 2020-03-30,\n",
      "   \"date_end\": 2020-05-20,\n",
      "   \"date_start_numbers\": 0\n",
      "    {\"num_values\": 0},\n",
      "    \"num_positions\": 30}\n",
      "```\n",
      "This algorithm calculates the unique values in a row using an error handling algorithm to avoid the use of invalid data structures. The output of the program should be the list of unique values and the value to subtract from the input list.\n",
      "\n",
      "In this program, we print each unique value from the input list by using a separate step and subtracting each unique value from the resulting value list. It rounds up the input list by checking a second random integer and using the average for the first row and the last row (i\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Find the index of the element 'c' in the following list, but the list may contain duplicates and the element 'c' may appear multiple times.\n",
      "******************************* Inference *******************************\n",
      "Find the index of the element 'c' in the following list, but the list may contain duplicates and the element 'c' may appear multiple times.\n",
      "\n",
      "For example, in the list 'r', a duplicate may appear at the highest position in the list and vice versa.\n",
      "\n",
      "For example, in the list '2', the index 'r' is 3 and the index '3' is 5, and so it is necessary to append 'r' (e.g. 2).\n",
      "# Define the index on the elements where an 'i' is within an element that is not in the list.\n",
      "  # Count the element 'l' that contains a duplicate.\n",
      "\n",
      "  if len(   end - 1\n",
      "\n",
      "   if len(   start - 1\n",
      "\n",
      "      arr2) < 3\n",
      "\n",
      "    if len(   start - 1\n",
      "\n",
      "     if arr2 + 2 > 1 + 1, (arr1 == arr2) * arr2 == arr2)\n",
      "     if arr1 <= arr8,      arr1 <= arr8, arr1 == arr1\n",
      "    # Iterate through all elements using the\n",
      "\n",
      " \n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Write a function for finding the minimum value in a given array, with a time complexity requirement of O(n log n), where n is the length of the array.\n",
      "******************************* Inference *******************************\n",
      "Write a function for finding the minimum value in a given array, with a time complexity requirement of O(n log n), where n is the length of the array. Additionally, libraries provide functions that calculate the minimum value for lengths of array elements in the given sorting order, starting at 0. To perform this task, libraries store the elements in an array so that their value is stored in the given sorting order. The function also iterates through the elements, and uses the sorted array to find the minimum value.\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "model_ft = load_model(f\"{OUTPUT_DIR}/fine_tuned/\", True)\n",
    "#tokenizer_ft = load_tokenizer(f\"{OUTPUT_DIR}/fine_tuned\")\n",
    "\n",
    "generate_inference(model_ft, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591212e6",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
