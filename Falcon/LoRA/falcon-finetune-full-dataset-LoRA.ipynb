{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-06T13:21:26.753711Z",
     "iopub.status.busy": "2024-08-06T13:21:26.753359Z",
     "iopub.status.idle": "2024-08-06T13:23:16.746125Z",
     "shell.execute_reply": "2024-08-06T13:23:16.745048Z",
     "shell.execute_reply.started": "2024-08-06T13:21:26.753680Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes==0.41.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.41.3)\n",
      "Requirement already satisfied: peft==0.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft==0.12.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft==0.12.0) (21.3)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft==0.12.0) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft==0.12.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft==0.12.0) (2.2.0)\n",
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft==0.12.0) (4.43.3)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft==0.12.0) (4.66.4)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft==0.12.0) (0.33.0)\n",
      "Requirement already satisfied: safetensors in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft==0.12.0) (0.4.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft==0.12.0) (0.24.5)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (2024.3.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.12.0) (4.12.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->peft==0.12.0) (3.1.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.12.0) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.12.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.12.0) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers->peft==0.12.0) (2024.7.24)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers->peft==0.12.0) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.12.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.12.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.12.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.12.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.12.0) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.12.0) (1.3.0)\n",
      "Requirement already satisfied: trl==0.8.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.8.6)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from trl==0.8.6) (2.2.0)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from trl==0.8.6) (4.43.3)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from trl==0.8.6) (1.26.4)\n",
      "Requirement already satisfied: accelerate in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from trl==0.8.6) (0.33.0)\n",
      "Requirement already satisfied: datasets in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from trl==0.8.6) (2.19.2)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from trl==0.8.6) (0.8.5)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.6) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.6) (4.12.1)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.6) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.6) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.6) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.6) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.6) (0.24.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.6) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.6) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.6) (2024.7.24)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.6) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.6) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.6) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.6) (4.66.4)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.6) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.6) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.6) (1.7.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate->trl==0.8.6) (5.9.8)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->trl==0.8.6) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->trl==0.8.6) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->trl==0.8.6) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->trl==0.8.6) (1.5.3)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->trl==0.8.6) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->trl==0.8.6) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->trl==0.8.6) (3.10.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.6) (2.3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.6) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.6) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.6) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.6) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.6) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.6) (4.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.31.0->trl==0.8.6) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.8.6) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.8.6) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.8.6) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.8.6) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (2.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl==0.8.6) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets->trl==0.8.6) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets->trl==0.8.6) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl==0.8.6) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets->trl==0.8.6) (1.16.0)\n",
      "Requirement already satisfied: datasets==2.19.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.19.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.19.2) (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.19.2) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.19.2) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.19.2) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.19.2) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.19.2) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.32.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.19.2) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.19.2) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.19.2) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.19.2) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.2) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.19.2) (3.10.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.19.2) (0.24.5)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.19.2) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets==2.19.2) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets==2.19.2) (2.3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets==2.19.2) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets==2.19.2) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets==2.19.2) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets==2.19.2) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets==2.19.2) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets==2.19.2) (4.0.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets==2.19.2) (4.12.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging->datasets==2.19.2) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.1->datasets==2.19.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.1->datasets==2.19.2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.1->datasets==2.19.2) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.1->datasets==2.19.2) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets==2.19.2) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets==2.19.2) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets==2.19.2) (1.16.0)\n",
      "Requirement already satisfied: transformers==4.43.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.43.3)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.43.3) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.43.3) (0.24.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.43.3) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.43.3) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.43.3) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.43.3) (2024.7.24)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.43.3) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.43.3) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.43.3) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.43.3) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.43.3) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.43.3) (4.12.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.43.3) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.43.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.43.3) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.43.3) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.43.3) (2024.2.2)\n",
      "Requirement already satisfied: tensorboard==2.17.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard==2.17.0) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard==2.17.0) (1.65.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard==2.17.0) (3.6)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard==2.17.0) (1.26.4)\n",
      "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard==2.17.0) (4.25.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard==2.17.0) (69.5.1)\n",
      "Requirement already satisfied: six>1.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard==2.17.0) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard==2.17.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from tensorboard==2.17.0) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard==2.17.0) (2.1.5)\n",
      "Requirement already satisfied: accelerate==0.33.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.33.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate==0.33.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate==0.33.0) (21.3)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate==0.33.0) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate==0.33.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate==0.33.0) (2.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate==0.33.0) (0.24.5)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate==0.33.0) (0.4.4)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0) (2024.3.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.33.0) (4.12.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.33.0) (3.1.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.33.0) (1.12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.33.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.33.0) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.33.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.33.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.33.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.33.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.33.0) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.33.0) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install bitsandbytes==0.41.3\n",
    "!pip3 install peft==0.12.0\n",
    "!pip3 install trl==0.8.6\n",
    "!pip3 install datasets==2.19.2\n",
    "!pip3 install transformers==4.43.3\n",
    "!pip3 install tensorboard==2.17.0\n",
    "!pip3 install accelerate==0.33.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T13:23:16.749368Z",
     "iopub.status.busy": "2024-08-06T13:23:16.748566Z",
     "iopub.status.idle": "2024-08-06T13:23:35.070946Z",
     "shell.execute_reply": "2024-08-06T13:23:35.069963Z",
     "shell.execute_reply.started": "2024-08-06T13:23:16.749326Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    TrainingArguments,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    "    logging,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T13:23:41.910163Z",
     "iopub.status.busy": "2024-08-06T13:23:41.909365Z",
     "iopub.status.idle": "2024-08-06T13:23:41.914689Z",
     "shell.execute_reply": "2024-08-06T13:23:41.913537Z",
     "shell.execute_reply.started": "2024-08-06T13:23:41.910128Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = \"Vezora/Tested-22k-Python-Alpaca\"\n",
    "model_id = \"tiiuae/falcon-rw-1b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T13:23:43.633801Z",
     "iopub.status.busy": "2024-08-06T13:23:43.633454Z",
     "iopub.status.idle": "2024-08-06T13:23:43.638947Z",
     "shell.execute_reply": "2024-08-06T13:23:43.637875Z",
     "shell.execute_reply.started": "2024-08-06T13:23:43.633774Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_tokenizer(model_id):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True, use_fast=False)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization config for QLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T13:23:46.436353Z",
     "iopub.status.busy": "2024-08-06T13:23:46.435985Z",
     "iopub.status.idle": "2024-08-06T13:23:46.442696Z",
     "shell.execute_reply": "2024-08-06T13:23:46.441791Z",
     "shell.execute_reply.started": "2024-08-06T13:23:46.436318Z"
    }
   },
   "outputs": [],
   "source": [
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T13:23:52.754870Z",
     "iopub.status.busy": "2024-08-06T13:23:52.753993Z",
     "iopub.status.idle": "2024-08-06T13:23:52.759961Z",
     "shell.execute_reply": "2024-08-06T13:23:52.759038Z",
     "shell.execute_reply.started": "2024-08-06T13:23:52.754838Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model(model_id, is_local=False):\n",
    "    print(\"Loading: \", model_id)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id, \n",
    "        #load_in_8bit=True,\n",
    "        #quantization_config=bnb_config,\n",
    "        device_map={\"\": 0},\n",
    "        local_files_only = is_local\n",
    "    )\n",
    "    \n",
    "    model.config.use_cache = False\n",
    "    model.config.pretraining_tp = 1\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T13:23:54.928332Z",
     "iopub.status.busy": "2024-08-06T13:23:54.927543Z",
     "iopub.status.idle": "2024-08-06T13:23:54.934958Z",
     "shell.execute_reply": "2024-08-06T13:23:54.933858Z",
     "shell.execute_reply.started": "2024-08-06T13:23:54.928287Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_inference(model, tokenizer):\n",
    "    pipe = pipeline(task='text-generation', model=model, tokenizer=tokenizer, max_length=256)\n",
    "\n",
    "    for prompt in prompts:\n",
    "        result = pipe(prompt)\n",
    "        print(\"******************************* PROMPT *******************************\")\n",
    "        print(prompt)\n",
    "        print(\"******************************* Inference *******************************\")\n",
    "        print(result[0]['generated_text'])\n",
    "        print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Inference Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T13:23:56.188544Z",
     "iopub.status.busy": "2024-08-06T13:23:56.188115Z",
     "iopub.status.idle": "2024-08-06T13:23:56.198829Z",
     "shell.execute_reply": "2024-08-06T13:23:56.197939Z",
     "shell.execute_reply.started": "2024-08-06T13:23:56.188510Z"
    }
   },
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"\"\"Can you design a program in Python that can predict the likelihood of a certain material becoming unstable under high pressure and temperature conditions? This can be calculated using the Gurney equation, which takes into account parameters such as the chemical composition and crystal structure of the material. Additionally, can you provide a real-world scenario where this program could be applied in the field of material science and engineering?\"\"\",\n",
    "    \"\"\"Write a Python function that returns the maximum value of the given set of integers: 1, 5, 23, and 9. The function should only use one line of code and must utilize the lambda function. Additionally, the function should be able to handle any set of integers provided as input, and should return an error message if any non-integer values are detected. The output should be displayed in a formatted table with the following columns: \"Input Set\", \"Maximum Value\". The table should also include a row for the given set of integers as well as a row for a randomly generated set of 10 integers between 1 and 100. Lastly, the function should be written in SQL and should be able to query a database table containing the input sets and their corresponding maximum values.\"\"\",\n",
    "    \"\"\"Create a function that takes two parameters, a number and a string, and returns an array with those two values in it. The string parameter should be checked if it is a valid string and if it contains only alphabetical characters. If the string is not valid (length less than 10 characters) or contains non-alphabetical characters, the function should return an empty array. Additionally, the number parameter should be restricted to a range between -1000 and 1000 (inclusive). The function should also check if the number is a prime number and return an empty array if it is not.\"\"\",\n",
    "    \"\"\"Given a string, convert it to upper case using only basic string manipulation operations. The string may contain punctuation marks, special characters, and spaces. String: This string should be in upper case!\"\"\",\n",
    "    \"\"\"Find the sum of the first 1000 prime numbers that are greater than 100.\"\"\",\n",
    "    \"\"\"Provide a function that finds the length of a string, but without using any built-in string length functions or methods, and without using any iteration or recursion.\"\"\",\n",
    "    \"\"\"Create a function that removes duplicates from an array and returns an array of the unique values. The function should only use O(1) additional space and have a time complexity of O(n), where n is the length of the input array. The input array can contain integers, floating-point numbers, strings, and nested arrays. The output array should be sorted in descending order. Additionally, the function should handle nested arrays correctly by recursively flattening them before removing duplicates.\"\"\",\n",
    "    \"\"\"Create a 3x4 NumPy array of random integers from 0 to 5, where each row should have at least one unique value.\"\"\",\n",
    "    \"\"\"Find the index of the element 'c' in the following list, but the list may contain duplicates and the element 'c' may appear multiple times.\"\"\",\n",
    "    \"\"\"Write a function for finding the minimum value in a given array, with a time complexity requirement of O(n log n), where n is the length of the array.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Fine-tuning inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T13:23:57.753362Z",
     "iopub.status.busy": "2024-08-06T13:23:57.752880Z",
     "iopub.status.idle": "2024-08-06T13:24:49.123943Z",
     "shell.execute_reply": "2024-08-06T13:24:49.122951Z",
     "shell.execute_reply.started": "2024-08-06T13:23:57.753330Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:  tiiuae/falcon-rw-1b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************* PROMPT *******************************\n",
      "Can you design a program in Python that can predict the likelihood of a certain material becoming unstable under high pressure and temperature conditions? This can be calculated using the Gurney equation, which takes into account parameters such as the chemical composition and crystal structure of the material. Additionally, can you provide a real-world scenario where this program could be applied in the field of material science and engineering?\n",
      "******************************* Inference *******************************\n",
      "Can you design a program in Python that can predict the likelihood of a certain material becoming unstable under high pressure and temperature conditions? This can be calculated using the Gurney equation, which takes into account parameters such as the chemical composition and crystal structure of the material. Additionally, can you provide a real-world scenario where this program could be applied in the field of material science and engineering?\n",
      "The Gurney equation is a mathematical model that can be used to predict the stability of a material under high pressure and temperature conditions. The equation is based on the fact that the material’s crystal structure and chemical composition will change under these conditions.\n",
      "The Gurney equation is a mathematical model that can be used to predict the stability of a material under high pressure and temperature conditions. The equation is based on the fact that the material’s crystal structure and chemical composition will change under these conditions.\n",
      "The Gurney equation is a mathematical model that can be used to predict the stability of a material under high pressure and temperature conditions. The equation is based on the fact that the material’s crystal structure and chemical composition will change under these conditions.\n",
      "The Gurney equation is a mathematical model that can be used to predict the stability of a material under\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Write a Python function that returns the maximum value of the given set of integers: 1, 5, 23, and 9. The function should only use one line of code and must utilize the lambda function. Additionally, the function should be able to handle any set of integers provided as input, and should return an error message if any non-integer values are detected. The output should be displayed in a formatted table with the following columns: \"Input Set\", \"Maximum Value\". The table should also include a row for the given set of integers as well as a row for a randomly generated set of 10 integers between 1 and 100. Lastly, the function should be written in SQL and should be able to query a database table containing the input sets and their corresponding maximum values.\n",
      "******************************* Inference *******************************\n",
      "Write a Python function that returns the maximum value of the given set of integers: 1, 5, 23, and 9. The function should only use one line of code and must utilize the lambda function. Additionally, the function should be able to handle any set of integers provided as input, and should return an error message if any non-integer values are detected. The output should be displayed in a formatted table with the following columns: \"Input Set\", \"Maximum Value\". The table should also include a row for the given set of integers as well as a row for a randomly generated set of 10 integers between 1 and 100. Lastly, the function should be written in SQL and should be able to query a database table containing the input sets and their corresponding maximum values.\n",
      "The function should be written in Python 3.6.\n",
      "The function should be written in Python 3.6.\n",
      "The function should be written in Python 3.6.\n",
      "The function should be written in Python 3.6.\n",
      "The function should be written in Python 3.6.\n",
      "The function should be written in Python 3.6.\n",
      "The function should be written in Python 3.6.\n",
      "The function should be written in Python 3.6.\n",
      "The function should be written\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Create a function that takes two parameters, a number and a string, and returns an array with those two values in it. The string parameter should be checked if it is a valid string and if it contains only alphabetical characters. If the string is not valid (length less than 10 characters) or contains non-alphabetical characters, the function should return an empty array. Additionally, the number parameter should be restricted to a range between -1000 and 1000 (inclusive). The function should also check if the number is a prime number and return an empty array if it is not.\n",
      "******************************* Inference *******************************\n",
      "Create a function that takes two parameters, a number and a string, and returns an array with those two values in it. The string parameter should be checked if it is a valid string and if it contains only alphabetical characters. If the string is not valid (length less than 10 characters) or contains non-alphabetical characters, the function should return an empty array. Additionally, the number parameter should be restricted to a range between -1000 and 1000 (inclusive). The function should also check if the number is a prime number and return an empty array if it is not.\n",
      "The function should return an array of strings that are the same length as the number and the string.\n",
      "The function should return an array of strings that are the same length as the number and the string.\n",
      "The function should return an array of strings that are the same length as the number and the string.\n",
      "The function should return an array of strings that are the same length as the number and the string.\n",
      "The function should return an array of strings that are the same length as the number and the string.\n",
      "The function should return an array of strings that are the same length as the number and the string.\n",
      "The function should return an array of strings that are the\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Given a string, convert it to upper case using only basic string manipulation operations. The string may contain punctuation marks, special characters, and spaces. String: This string should be in upper case!\n",
      "******************************* Inference *******************************\n",
      "Given a string, convert it to upper case using only basic string manipulation operations. The string may contain punctuation marks, special characters, and spaces. String: This string should be in upper case!\n",
      "String: This string should be in lower case!\n",
      "String: This string should be in mixed case!\n",
      "String: This string should be in all lower case!\n",
      "String: This string should be in all upper case!\n",
      "String: This string should be in all lower case!\n",
      "String: This string should be in all upper case!\n",
      "String: This string should be in all lower case!\n",
      "String: This string should be in all upper case!\n",
      "String: This string should be in all lower case!\n",
      "String: This string should be in all upper case!\n",
      "String: This string should be in all lower case!\n",
      "String: This string should be in all upper case!\n",
      "String: This string should be in all lower case!\n",
      "String: This string should be in all upper case!\n",
      "String: This string should be in all lower case!\n",
      "String: This string should be in all upper case!\n",
      "String: This string should be in all lower case!\n",
      "String: This string should be in all upper case!\n",
      "String\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Find the sum of the first 1000 prime numbers that are greater than 100.\n",
      "******************************* Inference *******************************\n",
      "Find the sum of the first 1000 prime numbers that are greater than 100.\n",
      "The sum of the first 1000 prime numbers is:\n",
      "100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100 + 100\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************* PROMPT *******************************\n",
      "Provide a function that finds the length of a string, but without using any built-in string length functions or methods, and without using any iteration or recursion.\n",
      "******************************* Inference *******************************\n",
      "Provide a function that finds the length of a string, but without using any built-in string length functions or methods, and without using any iteration or recursion.\n",
      "The function should return the length of the string, or an error if the string is not a valid UTF-8 string.\n",
      "The function should not use any built-in string length functions or methods.\n",
      "The function should not use any iteration or recursion.\n",
      "The function should not use any built-in string length functions or methods.\n",
      "The function should not use any iteration or recursion.\n",
      "The function should not use any built-in string length functions or methods.\n",
      "The function should not use any iteration or recursion.\n",
      "The function should not use any built-in string length functions or methods.\n",
      "The function should not use any iteration or recursion.\n",
      "The function should not use any built-in string length functions or methods.\n",
      "The function should not use any iteration or recursion.\n",
      "The function should not use any built-in string length functions or methods.\n",
      "The function should not use any iteration or recursion.\n",
      "The function should not use any built-in string length functions or methods.\n",
      "The function should not use any iteration or recursion.\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Create a function that removes duplicates from an array and returns an array of the unique values. The function should only use O(1) additional space and have a time complexity of O(n), where n is the length of the input array. The input array can contain integers, floating-point numbers, strings, and nested arrays. The output array should be sorted in descending order. Additionally, the function should handle nested arrays correctly by recursively flattening them before removing duplicates.\n",
      "******************************* Inference *******************************\n",
      "Create a function that removes duplicates from an array and returns an array of the unique values. The function should only use O(1) additional space and have a time complexity of O(n), where n is the length of the input array. The input array can contain integers, floating-point numbers, strings, and nested arrays. The output array should be sorted in descending order. Additionally, the function should handle nested arrays correctly by recursively flattening them before removing duplicates.\n",
      "The function should be written in C++.\n",
      "The function should be written in C++.\n",
      "The function should be written in C++.\n",
      "The function should be written in C++.\n",
      "The function should be written in C++.\n",
      "The function should be written in C++.\n",
      "The function should be written in C++.\n",
      "The function should be written in C++.\n",
      "The function should be written in C++.\n",
      "The function should be written in C++.\n",
      "The function should be written in C++.\n",
      "The function should be written in C++.\n",
      "The function should be written in C++.\n",
      "The function should be written in C++.\n",
      "The function should be written in C++.\n",
      "The function should be written in\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Create a 3x4 NumPy array of random integers from 0 to 5, where each row should have at least one unique value.\n",
      "******************************* Inference *******************************\n",
      "Create a 3x4 NumPy array of random integers from 0 to 5, where each row should have at least one unique value.\n",
      "import numpy as np import random import time import sys import matplotlib.pyplot as plt import numpy as np def create_array(n): \"\"\" Create a 3x4 NumPy array of random integers from 0 to 5, where each row should have at least one unique value. \"\"\" n = np.random.randint(0,5) for i in range(n): n[i] = random.randint(0,5) plt.plot(n[i], n[i], 'r') plt.show()\n",
      "The first thing we need to do is create a 3x4 NumPy array of random integers from 0 to 5, where each row should have at least one unique value.\n",
      "The first thing we need to do is create a 3x4 NumPy array of random integers from 0 to 5, where each row should have at least one unique value.\n",
      "The first thing we need to do is create a 3x4 NumPy array of random integers from 0 to 5, where each row should have at least one unique value.\n",
      "The first\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Find the index of the element 'c' in the following list, but the list may contain duplicates and the element 'c' may appear multiple times.\n",
      "******************************* Inference *******************************\n",
      "Find the index of the element 'c' in the following list, but the list may contain duplicates and the element 'c' may appear multiple times.\n",
      "1.\n",
      "2.\n",
      "3.\n",
      "4.\n",
      "5.\n",
      "6.\n",
      "7.\n",
      "8.\n",
      "9.\n",
      "10.\n",
      "11.\n",
      "12.\n",
      "13.\n",
      "14.\n",
      "15.\n",
      "16.\n",
      "17.\n",
      "18.\n",
      "19.\n",
      "20.\n",
      "21.\n",
      "22.\n",
      "23.\n",
      "24.\n",
      "25.\n",
      "26.\n",
      "27.\n",
      "28.\n",
      "29.\n",
      "30.\n",
      "31.\n",
      "32.\n",
      "33.\n",
      "34.\n",
      "35.\n",
      "36.\n",
      "37.\n",
      "38.\n",
      "39.\n",
      "40.\n",
      "41.\n",
      "42.\n",
      "43.\n",
      "44.\n",
      "45.\n",
      "46.\n",
      "47.\n",
      "48.\n",
      "49.\n",
      "50.\n",
      "51.\n",
      "52.\n",
      "53.\n",
      "54.\n",
      "55.\n",
      "56.\n",
      "57.\n",
      "58.\n",
      "59.\n",
      "60.\n",
      "61.\n",
      "62.\n",
      "63.\n",
      "64.\n",
      "65.\n",
      "66.\n",
      "67.\n",
      "68.\n",
      "69.\n",
      "70.\n",
      "71.\n",
      "72.\n",
      "73.\n",
      "74.\n",
      "75\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Write a function for finding the minimum value in a given array, with a time complexity requirement of O(n log n), where n is the length of the array.\n",
      "******************************* Inference *******************************\n",
      "Write a function for finding the minimum value in a given array, with a time complexity requirement of O(n log n), where n is the length of the array.\n",
      "The function should return the minimum value in the array.\n",
      "The function should return the minimum value in the array.\n",
      "The function should return the minimum value in the array.\n",
      "The function should return the minimum value in the array.\n",
      "The function should return the minimum value in the array.\n",
      "The function should return the minimum value in the array.\n",
      "The function should return the minimum value in the array.\n",
      "The function should return the minimum value in the array.\n",
      "The function should return the minimum value in the array.\n",
      "The function should return the minimum value in the array.\n",
      "The function should return the minimum value in the array.\n",
      "The function should return the minimum value in the array.\n",
      "The function should return the minimum value in the array.\n",
      "The function should return the minimum value in the array.\n",
      "The function should return the minimum value in the array.\n",
      "The function should return the minimum value in the array.\n",
      "The function should return the minimum value in the array.\n",
      "The function should return the minimum value in the array.\n",
      "The function should return the\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = load_model(model_id) \n",
    "tokenizer = load_tokenizer(model_id)\n",
    "generate_inference(model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEFT Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T13:24:49.125784Z",
     "iopub.status.busy": "2024-08-06T13:24:49.125494Z",
     "iopub.status.idle": "2024-08-06T13:24:49.130992Z",
     "shell.execute_reply": "2024-08-06T13:24:49.130126Z",
     "shell.execute_reply.started": "2024-08-06T13:24:49.125759Z"
    }
   },
   "outputs": [],
   "source": [
    "LORA_R = 16\n",
    "LORA_ALPHA = 32\n",
    "LORA_DROPOUT= 0.05\n",
    "LORA_TARGET_MODULES = [\n",
    "    \"q_proj\",\n",
    "    \"k_proj\",\n",
    "    \"v_proj\",\n",
    "    \"o_proj\",\n",
    "    \"gate_proj\",\n",
    "    \"up_proj\",\n",
    "    \"down_proj\",\n",
    "    \"lm_head\",\n",
    "]\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "MICRO_BATCH_SIZE = 4\n",
    "GRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE\n",
    "LEARNING_RATE = 3e-4\n",
    "TRAIN_STEPS = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T13:24:56.960391Z",
     "iopub.status.busy": "2024-08-06T13:24:56.959551Z",
     "iopub.status.idle": "2024-08-06T13:24:56.964659Z",
     "shell.execute_reply": "2024-08-06T13:24:56.963766Z",
     "shell.execute_reply.started": "2024-08-06T13:24:56.960358Z"
    }
   },
   "outputs": [],
   "source": [
    "peft_params = LoraConfig(\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    target_modules=LORA_TARGET_MODULES,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre process fine-tune data record "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T13:25:06.763633Z",
     "iopub.status.busy": "2024-08-06T13:25:06.762908Z",
     "iopub.status.idle": "2024-08-06T13:25:06.768457Z",
     "shell.execute_reply": "2024-08-06T13:25:06.767435Z",
     "shell.execute_reply.started": "2024-08-06T13:25:06.763599Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_function(example):\n",
    "    \"\"\"\n",
    "    Formatting function returning a list of samples (kind of necessary for SFT API).\n",
    "    \"\"\"\n",
    "    text = f\"### Instruction:\\n{example['instruction']}\\n\\n### Input:\\n{example['input']}\\n\\n### Response:\\n{example['output']}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T13:25:11.484439Z",
     "iopub.status.busy": "2024-08-06T13:25:11.484049Z",
     "iopub.status.idle": "2024-08-06T13:25:12.594973Z",
     "shell.execute_reply": "2024-08-06T13:25:12.594185Z",
     "shell.execute_reply.started": "2024-08-06T13:25:11.484409Z"
    }
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "dataset = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Datasets into multiple equal parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T13:25:27.160154Z",
     "iopub.status.busy": "2024-08-06T13:25:27.159490Z",
     "iopub.status.idle": "2024-08-06T13:25:27.554976Z",
     "shell.execute_reply": "2024-08-06T13:25:27.554143Z",
     "shell.execute_reply.started": "2024-08-06T13:25:27.160121Z"
    }
   },
   "outputs": [],
   "source": [
    "# instruction = dataset[\"train\"][\"instruction\"]\n",
    "# input = dataset[\"train\"][\"input\"]\n",
    "# output = dataset[\"train\"][\"output\"]\n",
    "\n",
    "# temp_dataset_1 = Dataset.from_dict({\"instruction\": instruction[:5500], \"input\": input[:5500], \"output\": output[:5500]})\n",
    "# dataset_1 = datasets.DatasetDict({\"train\": temp_dataset_1})\n",
    "\n",
    "# temp_dataset_2 = Dataset.from_dict({\"instruction\": instruction[5500:11000], \"input\": input[5500:11000], \"output\": output[5500:11000]})\n",
    "# dataset_2 = datasets.DatasetDict({\"train\": temp_dataset_2})\n",
    "\n",
    "# temp_dataset_3 = Dataset.from_dict({\"instruction\": instruction[11000:16500], \"input\": input[11000:16500], \"output\": output[11000:16500]})\n",
    "# dataset_3 = datasets.DatasetDict({\"train\": temp_dataset_3})\n",
    "\n",
    "# temp_dataset_4 = Dataset.from_dict({\"instruction\": instruction[16500:], \"input\": input[16500:], \"output\": output[16500:]})\n",
    "# dataset_4 = datasets.DatasetDict({\"train\": temp_dataset_4})\n",
    "\n",
    "\n",
    "# datasets = [dataset_1, dataset_2, dataset_3, dataset_4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T13:25:37.611425Z",
     "iopub.status.busy": "2024-08-06T13:25:37.610757Z",
     "iopub.status.idle": "2024-08-06T13:25:37.616470Z",
     "shell.execute_reply": "2024-08-06T13:25:37.615460Z",
     "shell.execute_reply.started": "2024-08-06T13:25:37.611393Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_split(dataset):\n",
    "    train_val = dataset[\"train\"].train_test_split(test_size=4000, shuffle=True, seed=42)\n",
    "    train_data = train_val[\"train\"]\n",
    "    val_data = train_val[\"test\"]\n",
    "\n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T13:25:46.001237Z",
     "iopub.status.busy": "2024-08-06T13:25:46.000587Z",
     "iopub.status.idle": "2024-08-06T13:25:46.026804Z",
     "shell.execute_reply": "2024-08-06T13:25:46.025998Z",
     "shell.execute_reply.started": "2024-08-06T13:25:46.001205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 837,632 || all params: 1,312,462,848 || trainable%: 0.0638\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_params)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# for param in model.parameters():\n",
    "#     if param.requires_grad:\n",
    "#         param.data = param.data.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T13:26:12.039665Z",
     "iopub.status.busy": "2024-08-06T13:26:12.039297Z",
     "iopub.status.idle": "2024-08-06T13:26:12.069640Z",
     "shell.execute_reply": "2024-08-06T13:26:12.068820Z",
     "shell.execute_reply.started": "2024-08-06T13:26:12.039639Z"
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR=\"/home/ec2-user/SageMaker/falcon/LoRA\"\n",
    "#OUTPUT_DIR=\"/kaggle/working/falcon/LoRA\"\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=OUTPUT_DIR,\n",
    "  num_train_epochs=3,\n",
    "  per_device_train_batch_size=4,\n",
    "  per_device_eval_batch_size=4,\n",
    "  gradient_accumulation_steps=4,\n",
    "  optim=\"paged_adamw_32bit\",\n",
    "  save_steps=1000,\n",
    "  logging_steps=1000,\n",
    "  learning_rate=0.0001,\n",
    "  eval_strategy=\"steps\",\n",
    "  weight_decay=0.001,\n",
    "  fp16=True,\n",
    "  bf16=False,\n",
    "  max_grad_norm=0.3,\n",
    "  max_steps=-1,\n",
    "  warmup_ratio=0.03,\n",
    "  group_by_length=True,\n",
    "  lr_scheduler_type=\"constant\",\n",
    "  report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T13:26:14.776135Z",
     "iopub.status.busy": "2024-08-06T13:26:14.775647Z",
     "iopub.status.idle": "2024-08-06T13:26:14.781752Z",
     "shell.execute_reply": "2024-08-06T13:26:14.780777Z",
     "shell.execute_reply.started": "2024-08-06T13:26:14.776097Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(train_dataset, eval_dataset, model, tokenizer, output_path):\n",
    "    \n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        max_seq_length=context_length,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        formatting_func=preprocess_function,\n",
    "        packing=True\n",
    "    )\n",
    "    \n",
    "    print(\"Model output path: \", f\"{output_path}/model/fine_tuned\")\n",
    "    \n",
    "    history = trainer.train()\n",
    "    model.save_pretrained(f\"{output_path}/model/fine_tuned\")\n",
    "    #tokenizer.save_pretrained(f\"{output_path}/tokenizer/fine_tuned\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T13:26:17.728115Z",
     "iopub.status.busy": "2024-08-06T13:26:17.727733Z",
     "iopub.status.idle": "2024-08-06T13:26:17.732324Z",
     "shell.execute_reply": "2024-08-06T13:26:17.731337Z",
     "shell.execute_reply.started": "2024-08-06T13:26:17.728082Z"
    }
   },
   "outputs": [],
   "source": [
    "context_length = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finetune model with dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T13:26:21.974597Z",
     "iopub.status.busy": "2024-08-06T13:26:21.974229Z",
     "iopub.status.idle": "2024-08-06T13:26:21.979989Z",
     "shell.execute_reply": "2024-08-06T13:26:21.979066Z",
     "shell.execute_reply.started": "2024-08-06T13:26:21.974561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuning with dataset 1 1722998765757\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "\n",
    "current_timestamp_ms = int(time.time() * 1000)\n",
    "print(\"finetuning with dataset 1\", current_timestamp_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T13:26:42.532472Z",
     "iopub.status.busy": "2024-08-06T13:26:42.531991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuning:  tiiuae/falcon-rw-1b\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a7836d6e5b400dbf5920ab5773ac79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1280 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output path:  /home/ec2-user/SageMaker/falcon/LoRA/full-dataset/model/fine_tuned\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8877' max='8877' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8877/8877 1:35:06, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.709300</td>\n",
       "      <td>1.517562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.461600</td>\n",
       "      <td>1.418721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.407400</td>\n",
       "      <td>1.383986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.373800</td>\n",
       "      <td>1.363913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.360100</td>\n",
       "      <td>1.350129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.351100</td>\n",
       "      <td>1.339514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.337000</td>\n",
       "      <td>1.332394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.330600</td>\n",
       "      <td>1.325872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/peft/utils/save_and_load.py:202: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1723004495237"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_DIR = \"/home/ec2-user/SageMaker/falcon/LoRA/full-dataset\"\n",
    "#BASE_DIR = \"/kaggle/working/gpt-2/dataset\"\n",
    "train_data, val_data = train_test_split(dataset)\n",
    "\n",
    "#index = \"full-data\"\n",
    "#model = load_model(model_id)\n",
    "#tokenizer = load_tokenizer(model_id)\n",
    "# model = get_peft_model(model, peft_params)\n",
    "# model.print_trainable_parameters()\n",
    "print(\"Fine-Tuning: \", model_id)\n",
    "model = train(train_data, val_data, model, tokenizer, f\"{BASE_DIR}\")\n",
    "\n",
    "current_timestamp_ms = int(time.time() * 1000)\n",
    "current_timestamp_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference after finetuning with dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T09:27:38.855264Z",
     "iopub.status.busy": "2024-08-06T09:27:38.854525Z",
     "iopub.status.idle": "2024-08-06T09:27:56.743091Z",
     "shell.execute_reply": "2024-08-06T09:27:56.742139Z",
     "shell.execute_reply.started": "2024-08-06T09:27:38.855233Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:  /home/ec2-user/SageMaker/falcon/LoRA/full-dataset/model/fine_tuned\n",
      "******************************* PROMPT *******************************\n",
      "Can you design a program in Python that can predict the likelihood of a certain material becoming unstable under high pressure and temperature conditions? This can be calculated using the Gurney equation, which takes into account parameters such as the chemical composition and crystal structure of the material. Additionally, can you provide a real-world scenario where this program could be applied in the field of material science and engineering?\n",
      "******************************* Inference *******************************\n",
      "Can you design a program in Python that can predict the likelihood of a certain material becoming unstable under high pressure and temperature conditions? This can be calculated using the Gurney equation, which takes into account parameters such as the chemical composition and crystal structure of the material. Additionally, can you provide a real-world scenario where this program could be applied in the field of material science and engineering?\n",
      "\n",
      "### Input:\n",
      "\n",
      "\n",
      "### Response:\n",
      "Sure, here's a Python program that can predict the stability of a material based on the chemical composition and crystal structure of the material. Here's a Python program that can predict the stability of a material based on the chemical composition and crystal structure of the material. Here's a Python program that can predict the stability of a material based on the chemical composition and crystal structure of the material. Here's a Python program that can predict the stability of a material based on the chemical composition and crystal structure of the material. Here's a Python program that can predict the stability of a material based on the chemical composition and crystal structure of the material. Here's a Python program that can predict the stability of a material based on the chemical composition and crystal structure of the material. Here's a Python program that can predict the stability of a material based on\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Write a Python function that returns the maximum value of the given set of integers: 1, 5, 23, and 9. The function should only use one line of code and must utilize the lambda function. Additionally, the function should be able to handle any set of integers provided as input, and should return an error message if any non-integer values are detected. The output should be displayed in a formatted table with the following columns: \"Input Set\", \"Maximum Value\". The table should also include a row for the given set of integers as well as a row for a randomly generated set of 10 integers between 1 and 100. Lastly, the function should be written in SQL and should be able to query a database table containing the input sets and their corresponding maximum values.\n",
      "******************************* Inference *******************************\n",
      "Write a Python function that returns the maximum value of the given set of integers: 1, 5, 23, and 9. The function should only use one line of code and must utilize the lambda function. Additionally, the function should be able to handle any set of integers provided as input, and should return an error message if any non-integer values are detected. The output should be displayed in a formatted table with the following columns: \"Input Set\", \"Maximum Value\". The table should also include a row for the given set of integers as well as a row for a randomly generated set of 10 integers between 1 and 100. Lastly, the function should be written in SQL and should be able to query a database table containing the input sets and their corresponding maximum values.\n",
      "\n",
      "### Input:\n",
      "\n",
      "\n",
      "### Response:\n",
      "Here's a Python function that returns the maximum value of a given set of integers:\n",
      "```python\n",
      "def max_value(set):\n",
      "                                                             \n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Create a function that takes two parameters, a number and a string, and returns an array with those two values in it. The string parameter should be checked if it is a valid string and if it contains only alphabetical characters. If the string is not valid (length less than 10 characters) or contains non-alphabetical characters, the function should return an empty array. Additionally, the number parameter should be restricted to a range between -1000 and 1000 (inclusive). The function should also check if the number is a prime number and return an empty array if it is not.\n",
      "******************************* Inference *******************************\n",
      "Create a function that takes two parameters, a number and a string, and returns an array with those two values in it. The string parameter should be checked if it is a valid string and if it contains only alphabetical characters. If the string is not valid (length less than 10 characters) or contains non-alphabetical characters, the function should return an empty array. Additionally, the number parameter should be restricted to a range between -1000 and 1000 (inclusive). The function should also check if the number is a prime number and return an empty array if it is not.\n",
      "\n",
      "### Input:\n",
      "\n",
      "\n",
      "### Response:\n",
      "Here is a Python function that takes two parameters, a number and a string, and returns an array with those two values in it:\n",
      "\n",
      "```python\n",
      "def is_prime(n):\n",
      "    if n < 10:\n",
      "        if n > 1000:\n",
      "           return []\n",
      "           if n < 10:\n",
      "            if n > 1000:\n",
      "             return []\n",
      "   \n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Given a string, convert it to upper case using only basic string manipulation operations. The string may contain punctuation marks, special characters, and spaces. String: This string should be in upper case!\n",
      "******************************* Inference *******************************\n",
      "Given a string, convert it to upper case using only basic string manipulation operations. The string may contain punctuation marks, special characters, and spaces. String: This string should be in upper case!\n",
      "\n",
      "### Input:\n",
      "\n",
      "\n",
      "### Response:\n",
      "Here is a Python program that converts a string to upper case using only basic string manipulation operations. The string may contain punctuation marks, special characters, and spaces.\n",
      "\n",
      "```python\n",
      "import string\n",
      "\n",
      "def convert_to_upper_case(string):\n",
      "    if len(string) == 1:\n",
      "           return string\n",
      "          return string\n",
      "```\n",
      "\n",
      "The program first checks if the string is a lowercase string. If it is, it converts it to upper case using the `convert_to_lower_case` function. If it is not, it converts it to lower case using the `convert_to_lower_case` function.\n",
      "\n",
      "The program then checks if the string contains any special characters. If it does, it converts them to lower case using the `convert_to_lower_case` function. If it does not, it converts them to\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Find the sum of the first 1000 prime numbers that are greater than 100.\n",
      "******************************* Inference *******************************\n",
      "Find the sum of the first 1000 prime numbers that are greater than 100.\n",
      "\n",
      "### Input:\n",
      "\n",
      "\n",
      "### Response:\n",
      "Here's the code that generates the output:\n",
      "\n",
      "```python\n",
      "import math\n",
      "\n",
      "def sum_prime_numbers(numbers):\n",
      "    sum_prime_numbers(numbers)\n",
      "    sum_prime_numbers(numbers)\n",
      "   sum_prime_numbers(numbers)\n",
      "   sum_prime_numbers(numbers)\n",
      "   sum_prime_numbers(numbers)\n",
      "   sum_prime_numbers(numbers)\n",
      "   sum_prime_numbers(numbers)\n",
      "   sum_prime_numbers(numbers)\n",
      "   sum_prime_numbers(numbers)\n",
      "   sum_prime_numbers(numbers)\n",
      "   sum_prime_numbers(numbers)\n",
      "   sum_prime_numbers(numbers)\n",
      "   sum_prime_numbers(numbers)\n",
      "   sum_prime_numbers(numbers)\n",
      "   sum_prime_numbers(numbers)\n",
      "  \n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************* PROMPT *******************************\n",
      "Provide a function that finds the length of a string, but without using any built-in string length functions or methods, and without using any iteration or recursion.\n",
      "******************************* Inference *******************************\n",
      "Provide a function that finds the length of a string, but without using any built-in string length functions or methods, and without using any iteration or recursion.\n",
      "\n",
      "### Input:\n",
      "\n",
      "\n",
      "### Response:\n",
      "Here's a possible implementation of the function:\n",
      "\n",
      "```python\n",
      "def find_length(string):\n",
      "    if len(string) == 0:\n",
      "          return len(string)\n",
      "         return len(string)\n",
      "         return len(string)\n",
      "        return len(string)\n",
      "      return len(string)\n",
      "    return len(string)\n",
      "    return len(string)\n",
      "    return len(string)\n",
      "   return len(string)\n",
      "   return len(string)\n",
      "   return len(string)\n",
      "   return len(string)\n",
      "   return len(string)\n",
      "   return len(string)\n",
      "   return len(string)\n",
      "   return len(string)\n",
      "   return len(string)\n",
      "   return len(string)\n",
      "  \n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Create a function that removes duplicates from an array and returns an array of the unique values. The function should only use O(1) additional space and have a time complexity of O(n), where n is the length of the input array. The input array can contain integers, floating-point numbers, strings, and nested arrays. The output array should be sorted in descending order. Additionally, the function should handle nested arrays correctly by recursively flattening them before removing duplicates.\n",
      "******************************* Inference *******************************\n",
      "Create a function that removes duplicates from an array and returns an array of the unique values. The function should only use O(1) additional space and have a time complexity of O(n), where n is the length of the input array. The input array can contain integers, floating-point numbers, strings, and nested arrays. The output array should be sorted in descending order. Additionally, the function should handle nested arrays correctly by recursively flattening them before removing duplicates.\n",
      "\n",
      "### Input:\n",
      "\n",
      "\n",
      "### Response:\n",
      "Here's a possible implementation of the function:\n",
      "\n",
      "```python\n",
      "def remove_duplicates(arr):\n",
      "    if arr[0] == 0:\n",
      "           if arr[1:] == 0:\n",
      "                if arr[2:] == 0:\n",
      "                 if arr[3:] == 0:\n",
      "                  if arr[4:] == 0:\n",
      "               \n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Create a 3x4 NumPy array of random integers from 0 to 5, where each row should have at least one unique value.\n",
      "******************************* Inference *******************************\n",
      "Create a 3x4 NumPy array of random integers from 0 to 5, where each row should have at least one unique value. The array should be sorted in ascending order. The array should be empty at the beginning. The array should be empty at the end. The array should be empty at the beginning and end. The array should be empty at the beginning and end. The array should be empty at the beginning and end. The array should be empty at the beginning and end. The array should be empty at the beginning and end. The array should be empty at the beginning and end. The array should be empty at the beginning and end. The array should be empty at the beginning and end. The array should be empty at the beginning and end. The array should be empty at the beginning and end. The array should be empty at the beginning and end. The array should be empty at the beginning and end. The array should be empty at the beginning and end. The array should be empty at the beginning and end. The array should be empty at the beginning and end. The array should be empty at the beginning and end. The array should be empty at the beginning and end. The array should be empty at the beginning and end. The array should be\n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Find the index of the element 'c' in the following list, but the list may contain duplicates and the element 'c' may appear multiple times.\n",
      "******************************* Inference *******************************\n",
      "Find the index of the element 'c' in the following list, but the list may contain duplicates and the element 'c' may appear multiple times.\n",
      "```python\n",
      "def find_element(element):\n",
      "                                                                                                                                                                                                                   \n",
      "====================================================================================================\n",
      "******************************* PROMPT *******************************\n",
      "Write a function for finding the minimum value in a given array, with a time complexity requirement of O(n log n), where n is the length of the array.\n",
      "******************************* Inference *******************************\n",
      "Write a function for finding the minimum value in a given array, with a time complexity requirement of O(n log n), where n is the length of the array. The function should also handle negative numbers and floating-point numbers.\n",
      "\n",
      "### Input:\n",
      "\n",
      "\n",
      "### Response:\n",
      "Here's a possible implementation of the function:\n",
      "\n",
      "```python\n",
      "def find_min_value(arr):\n",
      "    if arr[0] < arr[1]:\n",
      "            return arr[0]\n",
      "         if arr[0] < arr[1]:\n",
      "            return arr[0]\n",
      "            return arr[1]\n",
      "           return arr[2]\n",
      "           return arr[3]\n",
      "          return arr[4]\n",
      "         return arr[5]\n",
      "         return arr[6]\n",
      "         return arr[7]\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = load_model(f\"{BASE_DIR}/model/fine_tuned\") \n",
    "#tokenizer = load_tokenizer(f\"{BASE_DIR}1/tokenizer/fine_tuned\")\n",
    "generate_inference(model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune with model with dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T09:28:24.507956Z",
     "iopub.status.busy": "2024-08-06T09:28:24.507581Z",
     "iopub.status.idle": "2024-08-06T09:28:24.513193Z",
     "shell.execute_reply": "2024-08-06T09:28:24.512290Z",
     "shell.execute_reply.started": "2024-08-06T09:28:24.507927Z"
    }
   },
   "outputs": [],
   "source": [
    "current_timestamp_ms = int(time.time() * 1000)\n",
    "print(\"dataset 2 finetuning\", current_timestamp_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T09:28:25.500699Z",
     "iopub.status.busy": "2024-08-06T09:28:25.500325Z",
     "iopub.status.idle": "2024-08-06T09:28:42.943796Z",
     "shell.execute_reply": "2024-08-06T09:28:42.942862Z",
     "shell.execute_reply.started": "2024-08-06T09:28:25.500671Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(dataset_2)\n",
    "\n",
    "model_id = f\"{BASE_DIR}1/model/fine_tuned\"\n",
    "index = 2\n",
    "model = load_model(model_id)\n",
    "model = get_peft_model(model, peft_params)\n",
    "model.print_trainable_parameters()\n",
    "print(\"Fine-Tuning: \", model_id)\n",
    "model = train(train_data, val_data, model, tokenizer, f\"{BASE_DIR}{index}\")\n",
    "\n",
    "current_timestamp_ms = int(time.time() * 1000)\n",
    "current_timestamp_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference after finetuning with dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(f\"{BASE_DIR}2/model/fine_tuned\") \n",
    "generate_inference(model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune with model with dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_timestamp_ms = int(time.time() * 1000)\n",
    "print(\"dataset 3 finetuning\", current_timestamp_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(dataset_3)\n",
    "\n",
    "model_id = f\"{BASE_DIR}2/model/fine_tuned\"\n",
    "index = 3\n",
    "model = load_model(model_id)\n",
    "model = get_peft_model(model, peft_params)\n",
    "model.print_trainable_parameters()\n",
    "print(\"Fine-Tuning: \", model_id)\n",
    "model = train(train_data, val_data, model, tokenizer, f\"{BASE_DIR}{index}\")\n",
    "\n",
    "current_timestamp_ms = int(time.time() * 1000)\n",
    "current_timestamp_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference after finetuning with dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(f\"{BASE_DIR}3/model/fine_tuned\") \n",
    "generate_inference(model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune with model with dataset 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_timestamp_ms = int(time.time() * 1000)\n",
    "print(\"dataset 4 finetuning\", current_timestamp_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(dataset_4)\n",
    "\n",
    "model_id = f\"{BASE_DIR}3/model/fine_tuned\"\n",
    "index = 4\n",
    "model = load_model(model_id)\n",
    "model = get_peft_model(model, peft_params)\n",
    "model.print_trainable_parameters()\n",
    "print(\"Fine-Tuning: \", model_id)\n",
    "model = train(train_data, val_data, model, tokenizer, f\"{BASE_DIR}{index}\")\n",
    "\n",
    "current_timestamp_ms = int(time.time() * 1000)\n",
    "current_timestamp_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference after finetuning with dataset 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(f\"{BASE_DIR}4/model/fine_tuned\") \n",
    "generate_inference(model, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
